# Statistical methods in public policy research


<!-- README.md is generated from README.qmd. Please edit that file -->

[Andrew Heiss](https://www.andrewheiss.com) • Georgia State University

------------------------------------------------------------------------

<!-- badges: start -->

[![HTML preprint](https://img.shields.io/badge/HTML%20preprint-FF851B.png)](https://stats.andrewheiss.com/snoopy-spring/) [![PDF preprint](https://img.shields.io/badge/PDF%20preprint-3D9970.png)](https://stats.andrewheiss.com/snoopy-spring/heiss-statistics-public-policy.pdf) [![SocArXiv Preprint](https://img.shields.io/badge/SocArXiv%20preprint-10.31235%2Fosf.io%2Fcwymb__v1-blue)](https://doi.org/10.31235/osf.io/cwymb_v1)
<!-- badges: end -->

------------------------------------------------------------------------

> Andrew Heiss, “Statistical Methods in Public Policy Research”

------------------------------------------------------------------------

## Article summary

This essay provides an overview of statistical methods in public policy, focused primarily on the United States. The essay traces the historical development of quantitative approaches in policy research, from early ad hoc applications through the 19th and early 20th centuries, to the full institutionalization of statistical analysis in federal, state, local, and nonprofit agencies by the late 20th century. It then outlines three core methodological approaches to policy-centered statistical research across social science disciplines: description, explanation, and prediction. In descriptive work, researchers explore *what exists* and examine any variable of interest to understand their different distributions and relationships. In explanatory work, researchers ask *why does it exist* and *how can it be influenced*. The focus of the analysis is on explanatory variables (X) to either (1) accurately estimate their relationship with an outcome variable (Y), or (2) causally attribute the effect of specific explanatory variables on outcomes. In predictive work, researchers ask *what will happen next* and focus on the outcome variable (Y) and on generating accurate forecasts, classifications, and predictions from new data. For each approach, the essay examines key techniques, their applications in policy contexts, and important methodological considerations. The discussion then considers critical perspectives on quantitative policy analysis framed around issues related to a three-part “data imperative” where governments are driven to count, gather, and learn from data. Each of these imperatives entail substantial issues related to privacy, accountability, democratic participation, and epistemic inequalities—issues at odds with public sector values of transparency and openness. The conclusion identifies some emerging trends in public sector-focused data science, inclusive ethical guidelines, open research practices, and future directions for the field.

## 🕵️🌸: Note on “snoopy spring” project name

Because project titles change all the time with revisions, rewriting, and peer review, I used [{codename}](http://svmiller.com/codename/) to generate a [NICKA-style](https://www.designation-systems.net/usmilav/codenames.html) internal-to-me project name that won’t change.

``` r
library(codename)
codename_message()
#> code name generated by {codename} v.0.5.0. R version 4.3.2 (2023-10-31).

codename(type = "nicka", seed = "pubpol stats")
#> [1] "snoopy spring"
```

## Licenses

**Text and figures:** All prose and images are licensed under Creative Commons ([CC-BY-4.0](http://creativecommons.org/licenses/by/4.0/)).

**Code:** All code is licensed under the [MIT License](LICENSE.md).

## Contributions and Code of Conduct

We welcome contributions from everyone. Before you get started, please see our [contributor guidelines](CONTRIBUTING.md). Please note that this project is released with a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/0/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.
